4 4
86 86
Run instance segmentation grid-search:   0%|          | 0/4 [00:00<?, ?it/s]Run instance segmentation grid-search: 100%|██████████| 4/4 [00:00<00:00, 1857.94it/s]
Best grid-search result: 0.15348395417840804 with parmeters:
 center_distance_threshold = 0.5, boundary_distance_threshold = 0.3, distance_smoothing = 1.0, min_size = 100.0

Run inference for automatic mask generation:   0%|          | 0/86 [00:00<?, ?it/s]Run inference for automatic mask generation:   1%|          | 1/86 [00:00<01:02,  1.37it/s]Run inference for automatic mask generation:   2%|▏         | 2/86 [00:01<00:42,  1.96it/s]Run inference for automatic mask generation:   3%|▎         | 3/86 [00:01<00:35,  2.32it/s]Run inference for automatic mask generation:   5%|▍         | 4/86 [00:01<00:32,  2.50it/s]Run inference for automatic mask generation:   6%|▌         | 5/86 [00:02<00:30,  2.62it/s]Run inference for automatic mask generation:   7%|▋         | 6/86 [00:02<00:29,  2.72it/s]Run inference for automatic mask generation:   8%|▊         | 7/86 [00:02<00:27,  2.83it/s]Run inference for automatic mask generation:   9%|▉         | 8/86 [00:03<00:27,  2.87it/s]Run inference for automatic mask generation:  10%|█         | 9/86 [00:03<00:26,  2.92it/s]Run inference for automatic mask generation:  12%|█▏        | 10/86 [00:03<00:26,  2.89it/s]Run inference for automatic mask generation:  13%|█▎        | 11/86 [00:04<00:26,  2.86it/s]Run inference for automatic mask generation:  14%|█▍        | 12/86 [00:04<00:25,  2.90it/s]Run inference for automatic mask generation:  15%|█▌        | 13/86 [00:04<00:25,  2.91it/s]Run inference for automatic mask generation:  16%|█▋        | 14/86 [00:05<00:24,  2.93it/s]Run inference for automatic mask generation:  17%|█▋        | 15/86 [00:05<00:24,  2.94it/s]Run inference for automatic mask generation:  19%|█▊        | 16/86 [00:05<00:23,  2.94it/s]Run inference for automatic mask generation:  20%|█▉        | 17/86 [00:06<00:23,  2.95it/s]Run inference for automatic mask generation:  21%|██        | 18/86 [00:06<00:23,  2.96it/s]Run inference for automatic mask generation:  22%|██▏       | 19/86 [00:06<00:22,  2.95it/s]Run inference for automatic mask generation:  23%|██▎       | 20/86 [00:07<00:22,  2.91it/s]Run inference for automatic mask generation:  24%|██▍       | 21/86 [00:07<00:22,  2.89it/s]Run inference for automatic mask generation:  26%|██▌       | 22/86 [00:07<00:21,  2.91it/s]Run inference for automatic mask generation:  27%|██▋       | 23/86 [00:08<00:21,  2.91it/s]Run inference for automatic mask generation:  28%|██▊       | 24/86 [00:08<00:20,  2.97it/s]Run inference for automatic mask generation:  29%|██▉       | 25/86 [00:08<00:20,  2.93it/s]Run inference for automatic mask generation:  30%|███       | 26/86 [00:09<00:20,  2.92it/s]Run inference for automatic mask generation:  31%|███▏      | 27/86 [00:09<00:20,  2.93it/s]Run inference for automatic mask generation:  33%|███▎      | 28/86 [00:09<00:19,  2.92it/s]Run inference for automatic mask generation:  34%|███▎      | 29/86 [00:10<00:19,  2.95it/s]Run inference for automatic mask generation:  35%|███▍      | 30/86 [00:10<00:18,  2.95it/s]Run inference for automatic mask generation:  36%|███▌      | 31/86 [00:10<00:18,  2.95it/s]Run inference for automatic mask generation:  37%|███▋      | 32/86 [00:11<00:18,  2.94it/s]Run inference for automatic mask generation:  38%|███▊      | 33/86 [00:11<00:18,  2.91it/s]Run inference for automatic mask generation:  40%|███▉      | 34/86 [00:12<00:17,  2.92it/s]Run inference for automatic mask generation:  41%|████      | 35/86 [00:12<00:17,  2.98it/s]Run inference for automatic mask generation:  42%|████▏     | 36/86 [00:12<00:16,  2.96it/s]Run inference for automatic mask generation:  43%|████▎     | 37/86 [00:12<00:16,  2.99it/s]Run inference for automatic mask generation:  44%|████▍     | 38/86 [00:13<00:16,  2.95it/s]Run inference for automatic mask generation:  45%|████▌     | 39/86 [00:13<00:16,  2.92it/s]Run inference for automatic mask generation:  47%|████▋     | 40/86 [00:14<00:15,  2.93it/s]Run inference for automatic mask generation:  48%|████▊     | 41/86 [00:14<00:15,  2.92it/s]Run inference for automatic mask generation:  49%|████▉     | 42/86 [00:14<00:15,  2.93it/s]Run inference for automatic mask generation:  50%|█████     | 43/86 [00:15<00:14,  2.95it/s]Run inference for automatic mask generation:  51%|█████     | 44/86 [00:15<00:14,  2.93it/s]Run inference for automatic mask generation:  52%|█████▏    | 45/86 [00:15<00:14,  2.92it/s]Run inference for automatic mask generation:  53%|█████▎    | 46/86 [00:16<00:13,  2.93it/s]Run inference for automatic mask generation:  55%|█████▍    | 47/86 [00:16<00:13,  2.94it/s]Run inference for automatic mask generation:  56%|█████▌    | 48/86 [00:16<00:13,  2.90it/s]Run inference for automatic mask generation:  57%|█████▋    | 49/86 [00:17<00:12,  2.88it/s]Run inference for automatic mask generation:  58%|█████▊    | 50/86 [00:17<00:12,  2.88it/s]Run inference for automatic mask generation:  59%|█████▉    | 51/86 [00:17<00:12,  2.91it/s]Run inference for automatic mask generation:  60%|██████    | 52/86 [00:18<00:11,  2.92it/s]Run inference for automatic mask generation:  62%|██████▏   | 53/86 [00:18<00:11,  2.98it/s]Run inference for automatic mask generation:  63%|██████▎   | 54/86 [00:18<00:10,  2.96it/s]Run inference for automatic mask generation:  64%|██████▍   | 55/86 [00:19<00:10,  2.93it/s]Run inference for automatic mask generation:  65%|██████▌   | 56/86 [00:19<00:10,  2.94it/s]Run inference for automatic mask generation:  66%|██████▋   | 57/86 [00:19<00:09,  2.95it/s]Run inference for automatic mask generation:  67%|██████▋   | 58/86 [00:20<00:09,  2.98it/s]Run inference for automatic mask generation:  69%|██████▊   | 59/86 [00:20<00:09,  2.98it/s]Run inference for automatic mask generation:  70%|██████▉   | 60/86 [00:20<00:08,  2.99it/s]Run inference for automatic mask generation:  71%|███████   | 61/86 [00:21<00:08,  2.96it/s]Run inference for automatic mask generation:  72%|███████▏  | 62/86 [00:21<00:08,  2.94it/s]Run inference for automatic mask generation:  73%|███████▎  | 63/86 [00:21<00:07,  2.93it/s]Run inference for automatic mask generation:  74%|███████▍  | 64/86 [00:22<00:07,  2.95it/s]Run inference for automatic mask generation:  76%|███████▌  | 65/86 [00:22<00:07,  3.00it/s]Run inference for automatic mask generation:  77%|███████▋  | 66/86 [00:22<00:06,  2.97it/s]Run inference for automatic mask generation:  78%|███████▊  | 67/86 [00:23<00:06,  2.99it/s]Run inference for automatic mask generation:  79%|███████▉  | 68/86 [00:23<00:06,  2.97it/s]Run inference for automatic mask generation:  80%|████████  | 69/86 [00:23<00:05,  2.93it/s]Run inference for automatic mask generation:  81%|████████▏ | 70/86 [00:24<00:05,  2.94it/s]Run inference for automatic mask generation:  83%|████████▎ | 71/86 [00:24<00:05,  2.95it/s]Run inference for automatic mask generation:  84%|████████▎ | 72/86 [00:24<00:04,  2.96it/s]Run inference for automatic mask generation:  85%|████████▍ | 73/86 [00:25<00:04,  2.96it/s]Run inference for automatic mask generation:  86%|████████▌ | 74/86 [00:25<00:04,  2.98it/s]Run inference for automatic mask generation:  87%|████████▋ | 75/86 [00:25<00:03,  2.98it/s]Run inference for automatic mask generation:  88%|████████▊ | 76/86 [00:26<00:03,  3.00it/s]Run inference for automatic mask generation:  90%|████████▉ | 77/86 [00:26<00:02,  3.01it/s]Run inference for automatic mask generation:  91%|█████████ | 78/86 [00:26<00:02,  2.99it/s]Run inference for automatic mask generation:  92%|█████████▏| 79/86 [00:27<00:02,  2.97it/s]Run inference for automatic mask generation:  93%|█████████▎| 80/86 [00:27<00:02,  2.97it/s]Run inference for automatic mask generation:  94%|█████████▍| 81/86 [00:27<00:01,  2.97it/s]Run inference for automatic mask generation:  95%|█████████▌| 82/86 [00:28<00:01,  3.04it/s]Run inference for automatic mask generation:  97%|█████████▋| 83/86 [00:28<00:00,  3.01it/s]Run inference for automatic mask generation:  98%|█████████▊| 84/86 [00:28<00:00,  3.00it/s]Run inference for automatic mask generation:  99%|█████████▉| 85/86 [00:29<00:00,  2.98it/s]Run inference for automatic mask generation: 100%|██████████| 86/86 [00:29<00:00,  2.93it/s]Run inference for automatic mask generation: 100%|██████████| 86/86 [00:29<00:00,  2.91it/s]
Evaluating /mnt/lustre-grete/usr/u12649/scratch/models/pannuke_sam/cryonuseg_eval/instance/instance_segmentation_with_decoder/inference
86 86
Evaluate predictions:   0%|          | 0/86 [00:00<?, ?it/s]Evaluate predictions:   8%|▊         | 7/86 [00:00<00:01, 63.95it/s]Evaluate predictions:  16%|█▋        | 14/86 [00:00<00:01, 61.81it/s]Evaluate predictions:  24%|██▍       | 21/86 [00:00<00:01, 63.53it/s]Evaluate predictions:  33%|███▎      | 28/86 [00:00<00:00, 63.21it/s]Evaluate predictions:  41%|████      | 35/86 [00:00<00:00, 64.98it/s]Evaluate predictions:  49%|████▉     | 42/86 [00:00<00:00, 64.92it/s]Evaluate predictions:  58%|█████▊    | 50/86 [00:00<00:00, 66.94it/s]Evaluate predictions:  66%|██████▋   | 57/86 [00:00<00:00, 66.81it/s]Evaluate predictions:  74%|███████▍  | 64/86 [00:00<00:00, 67.02it/s]Evaluate predictions:  83%|████████▎ | 71/86 [00:01<00:00, 65.74it/s]Evaluate predictions:  92%|█████████▏| 79/86 [00:01<00:00, 67.64it/s]Evaluate predictions: 100%|██████████| 86/86 [00:01<00:00, 67.07it/s]Evaluate predictions: 100%|██████████| 86/86 [00:01<00:00, 65.91it/s]
        mSA      SA50      SA75
0  0.122006  0.241631  0.116539
